{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computational Approaches in the Study of Human Rights: Measuring Human Rights Conditions\n",
    "\n",
    "### Baekkwan Park:\n",
    "\n",
    "- any questions contact: baekkwan.park@gmail.com\n",
    "- This is basically the same as the .py file in the folder, but just a different format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # importing pandas for data read and management.\n",
    "\n",
    "# 1. Reading Data\n",
    "# reading data with pandas\n",
    "# Sample_Data.csv is in this folder.\n",
    "DATA = pd.read_csv('Sample_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# reading texts and annotations\n",
    "texts = DATA['texts']\n",
    "labels = DATA['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tokening Text Data\n",
    "# Building a dictionary to store the number of counts for each word in the data.\n",
    "from collections import defaultdict # useful dictionary modules from collections.\n",
    "\n",
    "# use a simple function for word counting\n",
    "def term_freq(tokens):\n",
    "\n",
    "    # making a dictionary\n",
    "    term_counts = defaultdict(int)\n",
    "\n",
    "    # reading each token and adding count to the dictionary\n",
    "    for token in tokens:\n",
    "        term_counts[token.lower()] += 1\n",
    "\n",
    "    return term_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # importing regex (regular expression) module\n",
    "\n",
    "text_counts = []\n",
    "token_names = []\n",
    "\n",
    "# reading text data one by one and tokenize words and counting them.\n",
    "for text in texts:\n",
    "\n",
    "    # making tokens\n",
    "    # using re to identify words.\n",
    "    tokens = re.findall(re.compile(r'\\b\\w\\w+\\b'), text)\n",
    "\n",
    "    # Counting each term frquency\n",
    "    text_count = term_freq(tokens)\n",
    "    text_counts.append(text_count)\n",
    "\n",
    "    # appending each token names\n",
    "    token_names.extend(text_count.keys())\n",
    "\n",
    "# identifying token names\n",
    "token_names_list = list(set(token_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Putting the word counts into a matrix form (document term matrix).\n",
    "\n",
    "matrix_base = []\n",
    "\n",
    "# from each word count from previous steps\n",
    "for text_count in text_counts:\n",
    "\n",
    "    matrix_rows = []\n",
    "\n",
    "    # for each unique word and matching the correspoding word counts\n",
    "    # and adding it to the matrix rows\n",
    "    for token_name in token_names_list:\n",
    "        matrix_rows.append(text_count.get(token_name, 0))\n",
    "\n",
    "    # aggregating all the matrix rows into the matrix base\n",
    "    matrix_base.append(matrix_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a sparse matrix\n",
    "from scipy.sparse import csr_matrix # import scipy sparse matrix tool\n",
    "\n",
    "# converting to sparse matrix\n",
    "matrix = csr_matrix(matrix_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see what you have just made--that is, document term matrix--in a nice dataframe,\n",
    "# try the following lines.\n",
    "\n",
    "# getting the indices for the matrix\n",
    "text_names = [i for i, v in enumerate(matrix)]\n",
    "\n",
    "# Displaying data structure with pandas dataframe\n",
    "dtm_df = pd.DataFrame(data=matrix.toarray(), index= text_names, columns = token_names_list)\n",
    "\n",
    "dtm_df # this won't look pretty, but it would look better if you run this in jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Modeling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Modeling\n",
    "# 4.1. have your data aready in the right format.\n",
    "# We bring what we have just made in the previous steps\n",
    "# Defining Text Data X\n",
    "\n",
    "# use numpy\n",
    "import numpy as np\n",
    "\n",
    "# matrix_base itslef is a list. converting to numpy array.\n",
    "X = np.array(matrix_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use other machine learning libraries such as scikit-learn, you would not have to do this,\n",
    "# but, we are going over what's inside those machine learning algorithms. We need to specify many things ourselves.\n",
    "\n",
    "# for example, we need to specify bias terms.\n",
    "bias_term = np.zeros((X.shape[0], 1))\n",
    "bias_term.fill(1) # simply assinging the value of 1.\n",
    "\n",
    "# Now, our text data matrix is X2 with the bias term.\n",
    "X2 = np.append(bias_term, X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2. You need to split the data X2 into training and testing set. (we do not do anything extra in this workshop).\n",
    "# We use train_test_split modules from scikit-learn.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Randomly splitting the data X2 into train and test (30 percent), the annotation labels into train and test (30 percent).\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X2, labels, test_size=0.30, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 Training\n",
    "# We do optimization manually to show step by step.\n",
    "np.random.seed(2) # setting a random seed for weight initialization\n",
    "\n",
    "theta = np.zeros((train_X.shape[1], 1)) # initial theta (weights)\n",
    "\n",
    "for i in range(200): # 200 iteration for gradient descent optimization\n",
    "\n",
    "    m = train_X.shape[0] # total number of data\n",
    "\n",
    "    z = np.dot(train_X, theta) # dot product between training data and our weights (theta)\n",
    "\n",
    "    # sigmoid function\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    # reformatting the annotation for matrix calculation\n",
    "    y = np.array(train_Y).reshape(-1,1)\n",
    "\n",
    "    # Loss Function\n",
    "    # In the workshop, we do not talk about regularization, but for comparison to scikit-learn results.\n",
    "    # It's included in this loss function.\n",
    "    J = (-1/m) * ((np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1-h))) + (0.1 * np.sum(theta)))\n",
    "\n",
    "    # updating weights\n",
    "    # learning rate is set manually here.\n",
    "    theta = theta - (0.0001 / m) * np.dot((train_X.T), (h - y))\n",
    "\n",
    "print ('loss: ', J) # see your loss\n",
    "print ('thetas: ', theta) # see your updated theta that will be used for prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 Testing\n",
    "# Just to avoid confusion, we name test inner product z_t.\n",
    "z_t = np.dot(test_X, theta)\n",
    "\n",
    "# calculating the predicted probability using sigmoid function.\n",
    "pred_probs= 1 / (1 + np.exp(-z_t))\n",
    "\n",
    "# We set the probability threshold at 0.5 for classification, otherwise set at 0.\n",
    "pred_labels = np.where(pred_probs > 0.5, 1, 0)\n",
    "pred_labels = [i[0] for i in pred_labels] # format better for comparing to the true labels.\n",
    "\n",
    "# Calculating model accuracy--that is, how mwny test items the trained model predicted correctly.\n",
    "\n",
    "correct_pred = 0 # counter set at 0.\n",
    "\n",
    "# comparing for each test data point\n",
    "for pred, truth in zip(pred_labels, test_Y): # remember, test_Y is our true labels for testing data.\n",
    "\n",
    "    # when they are the same count\n",
    "    if pred == truth:\n",
    "        correct_pred += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluation Metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "accuracy = correct_pred / len(test_Y)\n",
    "print ('model accuracy: ', accuracy) # expecting 0.933.\n",
    "\n",
    "# Creating a confusion matrix with scikit-learn modules.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# confusion matrix\n",
    "print (confusion_matrix(test_Y.tolist(), pred_labels))\n",
    "# expected outcome\n",
    "# array([[26,  0],\n",
    "#        [ 4, 30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** I would not recommend calculating the following metrics manually.\n",
    "# But, what we are doing here is to understand the processes step by step.\n",
    "# Thus, you need to understand the concept of precision, recall, and F-1 scores.\n",
    "\n",
    "# Calculating precision\n",
    "# # of true positives / total # of predicited positive (i.e. true positives + false positives)\n",
    "print (26/30)# precision for class 0\n",
    "print (30/30)# precision for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating recall\n",
    "# # of true positives/ total # of actual positives\n",
    "print (26/26) # recall for class 0\n",
    "print (30/34)# recall for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating F-1 score\n",
    "# 2*((precision*recall)/(precision+recall))\n",
    "print (2*((26/30)*(26/26))/((26/30) + (26/26))) # F1 for class 0\n",
    "print (2*((30/30)*(30/34))/((30/30) + (30/34)))# F1 for class 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Easy Way !!__\n",
    "\n",
    "- You can do all of the above steps in a very quickly without typing lines of code.\n",
    "- Here, we talk about how to use mahcine learning library such as scikit-learn, which is very powerful and conveinent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. reading data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. reading data\n",
    "import pandas as pd # you already did this, but this is a demo. So, do it again.\n",
    "\n",
    "DATA = pd.read_csv('Sample_Data.csv')\n",
    "texts = DATA['texts']\n",
    "labels = DATA['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Building a document term matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. building a document term matrix.\n",
    "from sklearn.feature_extraction.text import CountVectorizer # use CounterVectorizer module. EASY!!!!\n",
    "Vectorizer = CountVectorizer()\n",
    "X = Vectorizer.fit_transform(texts) # seriously, this is it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Data Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data split\n",
    "# this is the same as above.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.30, random_state = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train: We use LogisticRegression module from scikit-learn.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression() # call it\n",
    "classifier.fit(X_train, y_train)  #  and use it. This is it!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Prediction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. prediction\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Evaluation Metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6. Evauation metrics\n",
    "# As I said above, scikit learn has all these useful modules.\n",
    "# This is what I meant: I would not recommend doing these manually.\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print('confusion matrix: ', '\\n', confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __END__"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
